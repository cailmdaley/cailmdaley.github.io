# Epistemic Claims

**A visual language for scientific knowledge under uncertainty.**

---

## The Problem

AI systems produce scientific output faster than humans can verify. Kosmos claims six months of postdoc work in a day; Denario generates papers end-to-end. But these systems achieve only 57% accuracy on interpretation—and provide no infrastructure for verification.

When participation becomes negligible, consensus becomes theater.

## The Response

Claims as directed acyclic graphs. Each claim is a node with:
- **Statement**: What is being asserted
- **Kind**: The epistemic register (observation, interpretation, prediction)
- **Solidity**: Confidence as a single axis (0-1)
- **Dependencies**: What this claim rests on
- **Uncertainties**: Known limitations, stated explicitly
- **Evidence**: Supporting data
- **Provenance**: Human, AI, or human-verified-AI

The graph structure makes verification *checkpointable*. An agent or human can enter at any node, understand its dependencies, assess its solidity, and move on—without holding the entire project in context.

---

## Data Model

```javascript
{
  id: "claim_id",
  statement: "What is being asserted.",
  kind: "observation" | "interpretation" | "prediction",
  tier: 0,                    // Position in DAG (computed or explicit)
  correctness: 4,             // Legacy: 1-5 scale for visualization
  confidence: 4,              // Legacy: 1-5 scale for connector strands
  solidity: 0.7,              // Primary: 0-1 confidence measure
  depends_on: ["parent_id"],  // DAG structure
  provenance: "human" | "ai" | "verified",
  uncertainties: [
    "Known limitation 1",
    "Known limitation 2"
  ],
  evidence: {
    "metric_name": "value",
    "another_metric": "value"
  }
}
```

### On "Solidity"

A single confidence axis, not multiple metrics. The question isn't "how correct?" and "how confident?" separately—it's "how solid is this claim right now?"

- **0.9+**: Stake reputation on it
- **0.7-0.9**: Strong signal, some caveats
- **0.5-0.7**: Real signal, meaningful uncertainty
- **0.3-0.5**: Weak signal, substantial doubt
- **<0.3**: Unreliable

### On "Kind"

Three epistemic registers:

| Kind | Color | Meaning |
|------|-------|---------|
| **Observation** | Sepia (#8B7355) | Grounded in data. "We measured X." |
| **Interpretation** | Gold (#9A8B5C) | Meaning-making. "X suggests Y." |
| **Prediction** | Creek (#5A7B7B) | Reaching forward. "If X, then Y." |

### On "Provenance"

Who generated this claim?

- **Human**: Written by a person
- **AI**: Generated by an AI system
- **Verified**: AI-generated, human-verified

---

## Visual Encoding

### DAG Visualization

**Nodes**: Organic ellipses with concentric rings (Cajal-inspired). The noise-displaced shapes feel hand-drawn, alive—not mechanical.

- **Color** (hue): Correctness scale (red → yellow → green, 1-5)
- **Rings**: 4 concentric rings with fading opacity (0.5 → 0.125)
- **Fill**: Layered organic shapes, darker toward center

**Connectors**: Multi-strand bezier curves connecting rings.

- **Strand count**: Based on confidence (1-4 strands)
- **Strand opacity**: Matches ring opacity at connection point
- **Color**: Inherits from target node's correctness

**Layout**: Left-to-right by tier (Premises → Implications → Synthesis).

### Detail Card

On selection, the card shows:

```
┌─────────────────────────────────────────────────────┐
│ OBSERVATION                          (kind label)   │
│                                                     │
│ LLMs write code faster than humans for              │
│ well-specified tasks.               (statement)     │
│                                                     │
│ Uncertainties                                       │
│ – Speed advantage varies by task complexity         │
│ – Quality-speed tradeoff not fully characterized    │
│                                                     │
│ ┌─────────────┬──────────┬──────────┐              │
│ │ Evidence    │ Solidity │Provenance│              │
│ │ speedup 10x │   90%    │ Verified │              │
│ │ type: boil. │   ████░  │          │              │
│ └─────────────┴──────────┴──────────┘              │
└─────────────────────────────────────────────────────┘
```

Evidence, solidity, and provenance share a row at the bottom.

---

## Interaction

**Click** a node to select it. The graph highlights:
- Selected node: Full opacity
- Connected nodes (parents + children): 70% opacity
- Unconnected nodes: 30% opacity (dimmed)

Connectors follow the same logic—highlighted when touching selected node.

**Tier labels** below the graph: "Premises", "Implications", "Synthesis"

---

## Design Philosophy

This visualization lives in **Laboratory Mode** (see design-philosophy.md):

> After Cajal. The aesthetic of 19th-century scientific illustration before photography replaced the trained hand. Flowing lines rather than angular construction. Organic branching that follows the logic of growth.

The organic shapes, the stippled feel, the sepia-to-green palette—all signal "scientific notebook" rather than "corporate dashboard."

Uncertainty is metadata, not failure. A claim at 0.5 solidity is information. The trace is more valuable than the result.

---

## Implementation

Single HTML file: `/public/claims-demo/index.html`

**Dependencies**: D3.js v7 (loaded via CDN with defer)

**Key functions**:
- `renderDAG()` — Main visualization
- `organicEllipse(rx, ry, seed, scale)` — Noise-displaced ellipse path
- `noise2D(x, y, seed)` — Layered sine waves for smooth organic shapes
- `selectClaim(id)` — Update selection and render detail card
- `updateHighlighting()` — Dim/highlight based on selection
- `renderDetail(claim)` — Generate detail card HTML

**Embedding**: iframe in `/src/pages/science-ai.astro` with postMessage height sync.

---

## Future Directions

### Living Claims

The current system is static. Real science revises claims constantly. Possible directions:

- **Attention state**: Has this been reviewed? By whom? When?
- **Temperature**: Is this actively contested (hot) or settled (cold)?
- **Trajectory**: Is solidity rising or falling over time?

Not version history—*state*. A claim that nobody's looking at goes quiet. A claim being actively revised breathes.

### Multi-dimensional Confidence

Kosmos achieves 85% accuracy on data analysis but only 57% on interpretation. These are different kinds of knowing. Possible:

- Confidence over different dimensions (data / interpretation / reach)
- Explicit "conditioned on" clauses
- Qualitative states ("solid", "shaky", "contested") instead of numbers

### Integration with Snakemake

The epistemic-claims skill provides infrastructure for:
- Auto-generated `trace.auto.json` (evidence, artifacts, parameters)
- Human-edited `review.yaml` (claim, confidence, uncertainties)
- Dashboard generation from claim rules

This demo is standalone; the full system integrates with scientific workflows.

---

*First crystallized*: Claims dashboard for AI-science epistemics project
*Design register*: Laboratory Mode (Observational Patience)
